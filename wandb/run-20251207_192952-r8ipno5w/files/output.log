Epoch 1/20 | Train Loss: 1.5979 | Val Loss: 1.4784 | Val Acc: 43.36%
Epoch 2/20 | Train Loss: 1.2385 | Val Loss: 1.2269 | Val Acc: 57.96%
Epoch 3/20 | Train Loss: 1.1195 | Val Loss: 1.0379 | Val Acc: 65.49%
Epoch 4/20 | Train Loss: 1.0468 | Val Loss: 1.0241 | Val Acc: 69.03%
Epoch 5/20 | Train Loss: 0.9504 | Val Loss: 1.0752 | Val Acc: 66.81%
Epoch 6/20 | Train Loss: 0.9221 | Val Loss: 0.9461 | Val Acc: 65.04%
Epoch 7/20 | Train Loss: 0.8493 | Val Loss: 0.7680 | Val Acc: 75.22%
Epoch 8/20 | Train Loss: 0.8187 | Val Loss: 0.7925 | Val Acc: 73.45%
Epoch 9/20 | Train Loss: 0.7214 | Val Loss: 1.0212 | Val Acc: 72.57%
Epoch 10/20 | Train Loss: 0.7566 | Val Loss: 0.7803 | Val Acc: 75.22%
Epoch 11/20 | Train Loss: 0.7701 | Val Loss: 0.9605 | Val Acc: 68.58%
Epoch 12/20 | Train Loss: 0.6376 | Val Loss: 0.6445 | Val Acc: 76.55%
[34m[1mwandb[0m: [33mWARNING[0m Calling wandb.login() after wandb.init() has no effect.
Datos cargados: 904 entrenamiento, 226 test.
Clases: ['African Violet (Saintpaulia ionantha)', 'Aloe-Vera', 'Kalanchoe', 'Lily of the valley (Convallaria majalis)', 'Money Tree (Pachira aquatica)', 'Tulip']
ConvNet(
  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=50176, out_features=256, bias=True)
  (fc_bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=256, out_features=120, bias=True)
  (fc_bn2): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=120, out_features=60, bias=True)
  (fc4): Linear(in_features=60, out_features=6, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)

==================== Entrenando: 1_Base ====================
[34m[1mwandb[0m: [32m[41mERROR[0m The nbformat package was not found. It is required to save notebook history.
